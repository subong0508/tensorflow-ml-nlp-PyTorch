{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ch5-3-3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y64DjMjWfIUc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b662abe4-3824-4c4b-81d6-bff3503ff783"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwRNYZ0LfJ8A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f9a09753-62d9-423d-f71b-5ec00f223e7c"
      },
      "source": [
        "%cd /content/gdrive/My Drive/Colab Notebooks/tensorflow-ml-nlp-tf2/5.TEXT_SIM"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Colab Notebooks/tensorflow-ml-nlp-tf2/5.TEXT_SIM\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PECQTIcxfbJU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d40e500e-b9ea-4cc6-a46e-7d70f77ab593"
      },
      "source": [
        "import os\n",
        "\n",
        "if not os.path.exists('./data_out'):\n",
        "  os.makedirs('./data_out')\n",
        "else:\n",
        "  print(\"folder already exists\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "folder already exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m532Ct2_fKBd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn, optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XBVMwsnfKEQ",
        "colab_type": "text"
      },
      "source": [
        "## 데이터 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1c6Qe8ZfKUL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_IN_PATH = './data_in/'\n",
        "DATA_OUT_PATH = './data_out/'\n",
        "TRAIN_Q1_DATA_FILE = 'train_q1.npy'\n",
        "TRAIN_Q2_DATA_FILE = 'train_q2.npy'\n",
        "TRAIN_LABEL_DATA_FILE = 'train_label.npy'\n",
        "DATA_CONFIGS = 'data_configs.json'\n",
        "\n",
        "q1_data = np.load(open(DATA_IN_PATH + TRAIN_Q1_DATA_FILE, 'rb'))\n",
        "q2_data = np.load(open(DATA_IN_PATH + TRAIN_Q2_DATA_FILE, 'rb'))\n",
        "labels = np.load(open(DATA_IN_PATH + TRAIN_LABEL_DATA_FILE, 'rb'))\n",
        "prepro_configs = json.load(open(DATA_IN_PATH + DATA_CONFIGS, 'r'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oq1wLw4Ifmmo",
        "colab_type": "text"
      },
      "source": [
        "## 하이퍼파라미터 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B14wcBavfid3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_name = 'malstm_similarity'\n",
        "BATCH_SIZE = 128\n",
        "NUM_EPOCHS = 10\n",
        "VALID_SPLIT = 0.1\n",
        "\n",
        "kargs = {\n",
        "    'vocab_size': prepro_configs['vocab_size'],\n",
        "    'embedding_dimension': 100,\n",
        "    'lstm_dimension': 150,\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfEsiw-2fihK",
        "colab_type": "text"
      },
      "source": [
        "## DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFopE6WMfikH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "split = int(len(q1_data) * (1-VALID_SPLIT))\n",
        "\n",
        "q1_train, q1_val = q1_data[:split], q2_data[split:]\n",
        "q2_train, q2_val = q2_data[:split], q2_data[split:]\n",
        "labels_train, labels_val = labels[:split], labels[split:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwc_36_vfimo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "q1_train, q1_val = torch.LongTensor(q1_train), torch.LongTensor(q1_val)\n",
        "q2_train, q2_val = torch.LongTensor(q2_train), torch.LongTensor(q2_val)\n",
        "labels_train, labels_val = torch.FloatTensor(labels_train), torch.FloatTensor(labels_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYN5sMUJfirZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class TrainData(Dataset):\n",
        "  def __init__(self):\n",
        "    self.q1 = q1_train\n",
        "    self.q2 = q2_train\n",
        "    self.y = labels_train\n",
        "\n",
        "  def __getitem__(self, s):\n",
        "    return self.q1[s], self.q2[s], self.y[s]\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.y.shape[0]\n",
        "\n",
        "class ValData(Dataset):\n",
        "  def __init__(self):\n",
        "    self.q1 = q1_val\n",
        "    self.q2 = q2_val\n",
        "    self.y = labels_val\n",
        "\n",
        "  def __getitem__(self, s):\n",
        "    return self.q1[s], self.q2[s], self.y[s]\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.y.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YMBQh6Bfiux",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = TrainData()\n",
        "train_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_89Xtat1f31R",
        "colab_type": "text"
      },
      "source": [
        "## 모델 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1oSuqFIf335",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MaLSTMSimilarity(nn.Module):\n",
        "  def __init__(self, **kargs):\n",
        "    super(MaLSTMSimilarity, self).__init__()\n",
        "    self.vocab_size = kargs['vocab_size']\n",
        "    self.embedding_dim = kargs['embedding_dimension']\n",
        "    self.hidden_dim = kargs['lstm_dimension']\n",
        "    self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim, padding_idx=0)\n",
        "    self.lstm = nn.LSTM(input_size=self.embedding_dim, hidden_size=self.hidden_dim, batch_first=True)\n",
        "    self.fc = nn.Linear(11, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x1, x2 = x\n",
        "    x1, x2 = self.embedding(x1), self.embedding(x2)\n",
        "    x1, _ = self.lstm(x1)\n",
        "    x2, _ = self.lstm(x2)\n",
        "    out = torch.square(x1-x2).sum(axis=-1)\n",
        "    out = self.fc(out)\n",
        "    return torch.sigmoid(out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4vKrAbkfKYG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b4423771-f83d-498f-9916-b33d790e0414"
      },
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L57iChLffKSV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "q1_val, q2_val, labels_val = q1_val.to(device), q2_val.to(device), labels_val.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpezonEKkeIp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = MaLSTMSimilarity(**kargs).to(device)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.BCELoss().to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4sC6CT4keLr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "bc86c4f6-7889-43cc-ecc8-08b937697d15"
      },
      "source": [
        "model"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MaLSTMSimilarity(\n",
              "  (embedding): Embedding(76529, 100, padding_idx=0)\n",
              "  (lstm): LSTM(100, 150, batch_first=True)\n",
              "  (fc): Linear(in_features=11, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xm4bpTovfKP6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(train_loader=train_loader, model=model, optimizer=optimizer, num_epochs=NUM_EPOCHS):\n",
        "  model.train()\n",
        "\n",
        "  for epoch in range(1, NUM_EPOCHS+1):\n",
        "    for q1, q2, labels in train_loader:\n",
        "      q1, q2, labels = q1.to(device), q2.to(device), labels.to(device)\n",
        "      y_pred = model((q1, q2)).view_as(labels)\n",
        "      loss = criterion(y_pred, labels)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    print(f\"Epoch: {epoch}, Train Loss: {loss.item()}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTg4gmiBfKNJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "0dc0ee5c-3089-4f20-8e12-bdddaedb54b4"
      },
      "source": [
        "train()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1, Train Loss: 0.12939806282520294\n",
            "Epoch: 2, Train Loss: 1.9411799907684326\n",
            "Epoch: 3, Train Loss: 0.08472463488578796\n",
            "Epoch: 4, Train Loss: 0.12880872189998627\n",
            "Epoch: 5, Train Loss: 0.0007647815509699285\n",
            "Epoch: 6, Train Loss: 0.003443141933530569\n",
            "Epoch: 7, Train Loss: 0.0\n",
            "Epoch: 8, Train Loss: 0.02088308148086071\n",
            "Epoch: 9, Train Loss: 0.0602726936340332\n",
            "Epoch: 10, Train Loss: 0.001825448009185493\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giCWLcLefKKu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_dataset = ValData()\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jonZlLj9kp3b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval():\n",
        "  model.eval()\n",
        "  total_loss = 0\n",
        "  acc = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for q1, q2, labels in val_loader:\n",
        "      q1, q2, labels = q1.to(device), q2.to(device), labels.to(device)\n",
        "      output = model((q2, q2)).view_as(labels)\n",
        "      loss = criterion(output, labels) * BATCH_SIZE\n",
        "      total_loss += loss.item()\n",
        "      pred = (output.data >= 0.5).float()\n",
        "      acc += (pred == labels).sum()\n",
        "\n",
        "  return total_loss / len(val_dataset), acc.item() / len(val_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCryzYH7kp66",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "97e29828-c904-42ea-9fe0-9ba22b37a41b"
      },
      "source": [
        "eval()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.03256742157129627, 1.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SswJbCQbfKI0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(), f'./{model_name}.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6-TdYjZlZ9d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8fycntkl1x5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xQm8i6Xl11e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4MUPr63l14Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrJbcVQdl1_I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}